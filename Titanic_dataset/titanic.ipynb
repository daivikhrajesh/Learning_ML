{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((418, 11), (891, 12))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape, train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    def extract_last_name_and_title(name):\n",
    "        # Regex to match last name and title\n",
    "        match = re.match(r'^([^,]+),\\s*(\\w+\\.?)\\s*.*$', name.strip())\n",
    "        if match:\n",
    "            last_name = match.group(1).strip()\n",
    "            title = match.group(2).strip().replace('.', '') if match.group(2) else np.nan\n",
    "            return last_name, title\n",
    "        return name, np.nan\n",
    "\n",
    "    def extract_ticket_number(x):\n",
    "        try:\n",
    "            # Extract the last part after splitting by space\n",
    "            ticket_str = x.split(\" \")[-1]\n",
    "            # Convert to float\n",
    "            return float(ticket_str)\n",
    "        except ValueError:\n",
    "            # Return NaN if conversion fails\n",
    "            return np.nan\n",
    "\n",
    "    def extract_ticket_item(x):\n",
    "        items = x.split(\" \")\n",
    "        if len(items) == 1:\n",
    "            return np.nan\n",
    "        return \"_\".join(items[:-1])\n",
    "    \n",
    "    def extract_cabin_letter(x):\n",
    "        return x.split(\" \")[-1]\n",
    "\n",
    "    def extract_cabin_number(x):\n",
    "        items = x.split(\" \")\n",
    "        if len(items) == 1:\n",
    "            return np.nan\n",
    "        return \"_\".join(items[:-1])\n",
    "    \n",
    "    def count_words(name):\n",
    "        # Count the number of words in the name\n",
    "        return len(name.split())\n",
    "\n",
    "    def impute_numeric_mean(df):\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "        \n",
    "    def split_cabin(cabin):\n",
    "        if pd.isna(cabin):\n",
    "            return np.nan, np.nan\n",
    "        match = re.match(r'([A-Za-z])(\\d+)', cabin)\n",
    "        if match:\n",
    "            letter = match.group(1)\n",
    "            number = match.group(2)\n",
    "            return letter, number\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    # Impute missing values in numeric columns with mean\n",
    "    impute_numeric_mean(df)\n",
    "    \n",
    "    # Apply transformations\n",
    "    df[\"Ticket_number\"] = df[\"Ticket\"].apply(extract_ticket_number)\n",
    "    df[\"Ticket_item\"] = df[\"Ticket\"].apply(extract_ticket_item)\n",
    "    df[[\"Last_Name\", \"Title\"]] = df[\"Name\"].apply(extract_last_name_and_title).apply(pd.Series)\n",
    "    df[\"Name_Word_Count\"] = df[\"Name\"].apply(count_words)\n",
    "    df[[\"Cabin_Letter\", \"Cabin_Number\"]] = df[\"Cabin\"].apply(split_cabin).apply(pd.Series)\n",
    "    \n",
    "    # Remove the specified columns\n",
    "    df.drop(columns=[\"Name\", \"Ticket\", \"Cabin\", \"PassengerId\"], inplace=True)\n",
    "    \n",
    "    # Convert to floats\n",
    "    df['Cabin_Number'] = df['Cabin_Number'].astype(float)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess_data(train_df)\n",
    "test_df = preprocess_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Ticket_number</th>\n",
       "      <th>Ticket_item</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Name_Word_Count</th>\n",
       "      <th>Cabin_Letter</th>\n",
       "      <th>Cabin_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>21171.0</td>\n",
       "      <td>A/5</td>\n",
       "      <td>Braund</td>\n",
       "      <td>Mr</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>17599.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>7</td>\n",
       "      <td>C</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>3101282.0</td>\n",
       "      <td>STON/O2.</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>Miss</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>113803.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>7</td>\n",
       "      <td>C</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>373450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Mr</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>211536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montvila</td>\n",
       "      <td>Rev</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>112053.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graham</td>\n",
       "      <td>Miss</td>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>6607.0</td>\n",
       "      <td>W./C.</td>\n",
       "      <td>Johnston</td>\n",
       "      <td>Miss</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>111369.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Behr</td>\n",
       "      <td>Mr</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>370376.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dooley</td>\n",
       "      <td>Mr</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex        Age  SibSp  Parch     Fare Embarked  \\\n",
       "0           0       3    male  22.000000      1      0   7.2500        S   \n",
       "1           1       1  female  38.000000      1      0  71.2833        C   \n",
       "2           1       3  female  26.000000      0      0   7.9250        S   \n",
       "3           1       1  female  35.000000      1      0  53.1000        S   \n",
       "4           0       3    male  35.000000      0      0   8.0500        S   \n",
       "..        ...     ...     ...        ...    ...    ...      ...      ...   \n",
       "886         0       2    male  27.000000      0      0  13.0000        S   \n",
       "887         1       1  female  19.000000      0      0  30.0000        S   \n",
       "888         0       3  female  29.699118      1      2  23.4500        S   \n",
       "889         1       1    male  26.000000      0      0  30.0000        C   \n",
       "890         0       3    male  32.000000      0      0   7.7500        Q   \n",
       "\n",
       "     Ticket_number Ticket_item  Last_Name Title  Name_Word_Count Cabin_Letter  \\\n",
       "0          21171.0         A/5     Braund    Mr                4          NaN   \n",
       "1          17599.0          PC    Cumings   Mrs                7            C   \n",
       "2        3101282.0    STON/O2.  Heikkinen  Miss                3          NaN   \n",
       "3         113803.0         NaN   Futrelle   Mrs                7            C   \n",
       "4         373450.0         NaN      Allen    Mr                4          NaN   \n",
       "..             ...         ...        ...   ...              ...          ...   \n",
       "886       211536.0         NaN   Montvila   Rev                3          NaN   \n",
       "887       112053.0         NaN     Graham  Miss                4            B   \n",
       "888         6607.0       W./C.   Johnston  Miss                5          NaN   \n",
       "889       111369.0         NaN       Behr    Mr                4            C   \n",
       "890       370376.0         NaN     Dooley    Mr                3          NaN   \n",
       "\n",
       "     Cabin_Number  \n",
       "0             NaN  \n",
       "1            85.0  \n",
       "2             NaN  \n",
       "3           123.0  \n",
       "4             NaN  \n",
       "..            ...  \n",
       "886           NaN  \n",
       "887          42.0  \n",
       "888           NaN  \n",
       "889         148.0  \n",
       "890           NaN  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies_with_consistency(train_df, test_df, categorical_cols):\n",
    "    # Concatenate train and test datasets to get the complete set of categories\n",
    "    combined_df = pd.concat([train_df, test_df], axis=0, ignore_index=False)\n",
    "    \n",
    "    # Create dummy variables for the combined dataset\n",
    "    combined_dummies = pd.get_dummies(combined_df, columns=categorical_cols)\n",
    "    \n",
    "    # Determine the complete set of dummy columns\n",
    "    dummy_columns = combined_dummies.columns\n",
    "    \n",
    "    # Apply the same dummy columns to both train and test datasets\n",
    "    train_dummies = pd.get_dummies(train_df, columns=categorical_cols)\n",
    "    test_dummies = pd.get_dummies(test_df, columns=categorical_cols)\n",
    "    \n",
    "    # Reindex both train and test datasets to ensure they have the same dummy columns\n",
    "    train_dummies = train_dummies.reindex(columns=dummy_columns, fill_value=0)\n",
    "    test_dummies = test_dummies.reindex(columns=dummy_columns, fill_value=0)\n",
    "    \n",
    "    return train_dummies, test_dummies\n",
    "\n",
    "columns=['SibSp','Sex', 'Parch', 'Pclass', 'Embarked', 'Ticket_item', 'Last_Name', 'Title', 'Cabin_Letter']\n",
    "\n",
    "processed_train, processed_test = create_dummies_with_consistency(train_df, test_df, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_df, test_df = train_test_split(processed_train, test_size = .3, random_state = 24)\n",
    "\n",
    "y_train = test_df['Survived']\n",
    "x_train = test_df.drop(['Survived'], axis=1)\n",
    "y_val = validate_df['Survived']\n",
    "x_val = validate_df.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daivi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:43:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Evaluation Metrics:\n",
      "Accuracy: 0.8154\n",
      "Precision: 0.8173\n",
      "Recall: 0.6883\n",
      "F1 Score: 0.7473\n",
      "\n",
      "Random Forest Evaluation Metrics:\n",
      "Accuracy: 0.7978\n",
      "Precision: 0.7951\n",
      "Recall: 0.6599\n",
      "F1 Score: 0.7212\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "# Fill NaNs with 0s\n",
    "x_train = x_train.fillna(0)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict using XGBoost\n",
    "xgb_predictions = xgb_model.predict(x_val)\n",
    "\n",
    "# Fill NaNs with 0s\n",
    "x_val = x_val.fillna(0)\n",
    "\n",
    "# Predict using Random Forest\n",
    "rf_predictions = rf_model.predict(x_val)\n",
    "\n",
    "# Evaluate XGBoost model\n",
    "xgb_accuracy = accuracy_score(y_val, xgb_predictions)\n",
    "xgb_precision = precision_score(y_val, xgb_predictions)\n",
    "xgb_recall = recall_score(y_val, xgb_predictions)\n",
    "xgb_f1 = f1_score(y_val, xgb_predictions)\n",
    "\n",
    "# Evaluate Random Forest model\n",
    "rf_accuracy = accuracy_score(y_val, rf_predictions)\n",
    "rf_precision = precision_score(y_val, rf_predictions)\n",
    "rf_recall = recall_score(y_val, rf_predictions)\n",
    "rf_f1 = f1_score(y_val, rf_predictions)\n",
    "\n",
    "# Print Evaluation Metrics\n",
    "print(\"XGBoost Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {xgb_accuracy:.4f}\")\n",
    "print(f\"Precision: {xgb_precision:.4f}\")\n",
    "print(f\"Recall: {xgb_recall:.4f}\")\n",
    "print(f\"F1 Score: {xgb_f1:.4f}\")\n",
    "\n",
    "print(\"\\nRandom Forest Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Precision: {rf_precision:.4f}\")\n",
    "print(f\"Recall: {rf_recall:.4f}\")\n",
    "print(f\"F1 Score: {rf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the survived column (this was introduced in consistency function)\n",
    "test_df = processed_test.drop(columns=['Survived'])\n",
    "\n",
    "# Apply the trained XGBoost model to test_df\n",
    "xgb_predictions_test = xgb_model.predict(test_df)\n",
    "\n",
    "# Convert predictions to DataFrame and set index as 'Passenger Id'\n",
    "predictions_df = pd.DataFrame({\n",
    "    'PassengerId': test_df.index,\n",
    "    'Survived': xgb_predictions_test\n",
    "})\n",
    "\n",
    "predictions_df['PassengerId'] = predictions_df['PassengerId'] + 892\n",
    "predictions_df.to_csv('final.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = pd.read_csv('final.csv')\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
